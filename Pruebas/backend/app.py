# main_chat.py

from langchain_ollama import OllamaLLM
from langchain_core.prompts import ChatPromptTemplate
from bussiness_info import info
from extractor import extraer_datos
from funciones import buscar_vuelos

# Template para el mensaje al modelo
template = """
Eres un asistente de viajes que responde en espa침ol.

Informaci칩n de la empresa:
{bussiness_info}

Historial de conversaci칩n:
{context}

Usuario: {question}
Asistente:
"""

# Configuraci칩n del modelo Llama 3.2 (1B)
model = OllamaLLM(
    model="llama3.2",
    temperature=0.7,
    system="""
Eres un asistente de viajes en espa침ol. Tu tarea es ayudar al usuario a buscar vuelos.

Si el usuario saluda o no dice nada 칰til, resp칩ndele educadamente y preg칰ntale desde d칩nde desea volar.

Haz preguntas breves si faltan datos como:
- origen
- destino
- fecha de salida
- tipo de pasajero

No inventes datos. No repitas informaci칩n. No hables de cosas fuera del contexto de vuelos.
"""
)

# Encadenar el prompt y el modelo
prompt = ChatPromptTemplate.from_template(template)
chain = prompt | model

# Estado global de los datos de vuelo
datos_vuelo = {
    "origen": None,
    "destino": None,
    "fecha_salida": None,
    "fecha_regreso": None,
    "tipo_pasajero": None
}

# Funci칩n para actualizar los datos extra칤dos manteniendo los anteriores
def actualizar_datos_vuelo(nuevos_datos):
    for campo, valor in nuevos_datos.items():
        if valor not in [None, "null", ""]:
            datos_vuelo[campo] = valor

# Chat principal
def chat():
    print("游띪 Bienvenido al chatbot de vuelos")
    context = ""

    while True:
        question = input("T칰: ").strip()
        if question.lower() in ["stop", "salir"]:
            print("Bot: Gracias por usar el chatbot. 춰Buen viaje! 九걾잺")
            break

        # Llamada al modelo de lenguaje
        result = chain.invoke({
            "bussiness_info": info,
            "context": context,
            "question": question
        })
        respuesta = result.content if hasattr(result, 'content') else str(result)
        print("Bot:", respuesta)

        # Acumular contexto para futuras respuestas
        context += f"T칰: {question}\nBot: {respuesta}\n"

        # Extraer datos solo si es relevante
        palabras_clave = ["vuelo", "viaje", "reservar", "salida", "ida", "llegada", "regreso", "origen", "destino", "fecha"]
        if any(palabra in question.lower() for palabra in palabras_clave):
            nuevos_datos = extraer_datos(question)
            print("游꿢 Datos extra칤dos:", nuevos_datos)
            actualizar_datos_vuelo(nuevos_datos)
            print("游 Estado acumulado:", datos_vuelo)

        # Condici칩n m칤nima para lanzar b칰squeda
        if all([datos_vuelo["origen"], datos_vuelo["destino"], datos_vuelo["fecha_salida"], datos_vuelo["tipo_pasajero"]]):
            vuelos = buscar_vuelos(
                origen=datos_vuelo["origen"],
                destino=datos_vuelo["destino"],
                fecha_salida=datos_vuelo["fecha_salida"],
                fecha_regreso=datos_vuelo["fecha_regreso"],
                pasajeros=1,
                tipo_pasajero=datos_vuelo["tipo_pasajero"]
            )
            print("Bot:", vuelos)
            context += f"Bot: {vuelos}\n"

            # Reiniciar b칰squeda (puedes cambiar esto si deseas que siga preguntando m치s)
            for k in datos_vuelo:
                datos_vuelo[k] = None
            print("游댃 Datos reiniciados para una nueva b칰squeda.")


if __name__ == "__main__":
    chat()
